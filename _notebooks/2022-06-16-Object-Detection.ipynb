{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection\n",
    "> An introduction to the world of Deep Learning.\n",
    "\n",
    "* toc: true\n",
    "* badges: true\n",
    "* comments: true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Object detection is a computer vision task that involves two tasks: \n",
    "1. Localizing one or more objects within an image, and \n",
    "2. Classifying each object in the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOLO is a family of object detection networks that improved over the years throught the following version; YOLOv1, YOLOv2, YOLOv3 and YOLOv4. The YOLO family of models is a series of end-to-end deep learning models designed for fast object detection, developed by Joseph Redmon, etal. Thought is is no longer the most accurate object detection algorithms, it is a very good choice when you need real-time detection, withoug loss of too much accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How it works**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOLO first generate potential bounding boxes in an image and then run a classifier on these proposed boxes. \n",
    "After classification, post-processsing is used to refine the bounding boxes, eliminate duplicate detctions and rescore the bxes based on other \n",
    "objects in the scene."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step1: It divides image into SxS grid cells.\n",
    "\n",
    "![](../images/od1.PNG)\n",
    "\n",
    "Step2: Each cell will generate B objects and produce the output in the format. (tx, ty, tw, th, po) + number of classes with score. \n",
    "\n",
    "![](../images/od2.PNG)\n",
    "\n",
    "Step3: If we are trying to detect dog and cat (i.e. class=2) and B = 1 then the 1st grid cell will produce center coordinate of grid cell, width and height (randomly generated) of 1 image and the objectness score which should be close to zero as there is no center of object in 1st grid. And class score of dog and cat.\n",
    "\n",
    "Step4: Similarly the centered cess (heighlighted in red) will produce output (x,y) - center of the cell, (w, h) - width and height of dog highlighted in yellow and conditional probability of dog and cat.\n",
    "\n",
    "Step5: Note: Except to width and height of images, will be generated randomly so except for the values of (tx, ty) all the remaining value will be random and incorrect. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* When we start training the algorithm we pass image as well as the co-ordinate of objects in the format (x, y, w, h) where (x, y) represent center of each object and (w, h) is the width and height of objects. \n",
    "* In the first step model will take the image and product co-ordinate of each cell along with width and height of object, objectness score and class score. \n",
    "* These values will get compared with the original values and with each iteration model will improve all the values and train the networl."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
