---
toc: true
layout: post
description: Some most common operation using Pytorch.
categories: [markdown]
title: Pytorch - Your Favourite Deep Learning Library
---
# Some most common operation using Pytorch

Pytorch is an open source machine learning library probably easiest to start with. It is built by Facebook. In this notebook I will write and discuss five most common and important functions in pytorch.

1. torch.transpose()
2. torch.stack()
3. torch.where()
4. torch.backward()
5. torch.add()

![]({{ site.baseurl }}/images/torch.png "pytorch")

## 1. transpose()
In linear algebra, the transpose of a matrix is an operator which flips a matrix over its diagonal, that is it switches the row and column indices of the matrix by producing. Here we will transpose tensor using pytorch transpose function.

![]({{ site.baseurl }}/i{{ site.baseurl }}ges/t1.jpg "transpose1")

x is a 2-D tensor. we swapped dimension 0 to dimension 1 using torch.transpose()

![]({{ site.baseurl }}/images/t2.png "transpose2")

we swapped dimension 1 to dimension 0.

![]({{ site.baseurl }}/images/t3.png "transpose3")

We need to put the dimension which is going to be swapped without. And if we put same dimension twice it has no effect.

Transpose function is very useful while matrix multiplication

## 2. stack()

This function conconate every new tensor in new dimension. It add every new tensor to additional dimension

![]({{ site.baseurl }}/images/s1.png "stack")

Here we stacked b over a and created an additional dimesion.

![]({{ site.baseurl }}/images/s2.png "stack")

Here b is the stack of 3 a tensor
![]({{ site.baseurl }}/images/s3.png "stack")

To make an stack, all tensors need to be in equal size.

While working with images data, stack function is useful for numerical calculation.

For example- to calculate statistical values like mean, median, etc. Stacking makes easy to calculate all of these.

## 3. where()
Returns tensor of element with given condition

![]({{ site.baseurl }}{{ site.baseurl }}mages/w1.png "where")

torch.where() returns a tensor with values y if x>0 else it return x.

![]({{ site.baseurl }}/images/w2.png "where")

here we find the difference between x and y. This function can be used as a loss function in binary classification problems, where the target variable is similar like x and predicted value like y.

![]({{ site.baseurl }}/images/w3.png "where")

If size of y is less then x then pytorch automatically expand y to the size of x without additional memory. However if the size of y is greater then x, the it doesn't work.

This function can be used as a loss function in binary classification problems.

## 4. backward()
This function is most important function in mathine leanring. It calculate the gradient of a function.

![]({{ site.baseurl }}/images/b1.png "backward")
![]({{ site.baseurl }}/images/b2.png "backward")
![]({{ site.baseurl }}/images/b3.png "backward")

To calculate gradient we need to set requires_grad = True.

While updating the weight in gradient descent backword function is used to update the weight.

## 5. add()

To add two tensor

![]({{ site.baseurl }}/images/a1.png "add")

Here add function just work like + operator.

![]({{ site.baseurl }}/images/a2.png "add")

As you can see above the size of y is not the size of x. But pytorch expand the size of y by replacating its data and do elementwise operation.

![]({{ site.baseurl }}/images/a3.png "add")

Here the size of y is greator then the size of x but x doesn't expand. Pytorch expand in every dimension, if it increase the dimension of x then it will become 3*3 still doesn't match the size of y.

It is very helpful while doing tensor operation. Additional operator is one of the most used operator

## Conclusion
We have covered five most useful pytorch function. Go the the pytorch documentation and write five function of your choice.

**Reference**

* [Official Pytorch Documentation](https://pytorch.org/docs/stable/tensors.html)